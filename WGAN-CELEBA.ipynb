{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b38187-86b0-452a-963d-8d5f3bbd14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Reshape, Flatten, Input, BatchNormalization, Conv2D, Conv2DTranspose, Dropout, UpSampling2D, AveragePooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load CelebA dataset\n",
    "celeba_data, info = tfds.load('celeb_a', split='train', with_info=True)\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset images:\n",
    "    - Resize the images to 256x256.\n",
    "    - Normalize the images to [-1, 1].\n",
    "    \"\"\"\n",
    "    def _preprocess_img(img):\n",
    "        # Resize the image\n",
    "        img = tf.image.resize(img, (256, 256))\n",
    "        # Normalise to [-1, 1]\n",
    "        img = (img - 127.5) / 127.5\n",
    "        return img\n",
    "\n",
    "    return dataset.map(lambda x: (_preprocess_img(x['image']), x['attributes']), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 8  # * can reduce if memory issues\n",
    "EPOCHS = 2000  \n",
    "NOISE_DIM = 200  # Noise dimension for generator input\n",
    "SAVE_INTERVAL = 25  # Frequency to save generated images for visualisation\n",
    "TRAINING_RATIO = 5  # Number of discriminator updates per generator update\n",
    "\n",
    "# Preprocess and batch the dataset\n",
    "celeba_dataset_processed = preprocess_dataset(celeba_data).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "# For the training function, we need the data in numpy format\n",
    "num_samples = 1000  # You can adjust this value based on available memory\n",
    "\n",
    "\n",
    "IMG_SHAPE = (512, 512, 3)\n",
    "\n",
    "def build_simplified_generator():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Start with 8x8 spatial resolution\n",
    "    model.add(Dense(128 * 8 * 8, activation=\"relu\", input_shape=(NOISE_DIM,)))\n",
    "    model.add(Reshape((8, 8, 128)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # UpSample to 16x16\n",
    "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    # UpSample to 32x32\n",
    "    model.add(Conv2DTranspose(32, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    # UpSample to 64x64\n",
    "    model.add(Conv2DTranspose(16, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    # UpSample to 128x128\n",
    "    model.add(Conv2DTranspose(8, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    # UpSample to 256x256\n",
    "    model.add(Conv2DTranspose(3, kernel_size=4, strides=2, padding=\"same\", activation=\"tanh\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_simplified_discriminator():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=4, strides=2, padding=\"same\", input_shape=(256, 256, 3)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Instantiate the new models\n",
    "generator_512 = build_simplified_generator()\n",
    "discriminator_512 = build_simplified_discriminator()\n",
    "\n",
    "# Optimisers with Two Timescale Update Rule (TTUR)\n",
    "optimizer_gen = tf.keras.optimizers.Adam(0.0001, beta_1=0.5, beta_2=0.9)\n",
    "optimizer_disc = tf.keras.optimizers.Adam(0.0004, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "# Loss function (Wasserstein loss)\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return -tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "# Compilation\n",
    "generator_512.compile(optimizer=optimizer_gen, loss=wasserstein_loss)\n",
    "discriminator_512.compile(optimizer=optimizer_disc, loss=wasserstein_loss)\n",
    "\n",
    "# Combined model for training the generator\n",
    "z = Input(shape=(NOISE_DIM,))\n",
    "img = generator_512(z)\n",
    "discriminator_512.trainable = False\n",
    "valid = discriminator_512(img)\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss=wasserstein_loss, optimizer=optimizer_gen)\n",
    "\n",
    "def train_gan_512(dataset, epochs, batch_size=BATCH_SIZE, save_interval=SAVE_INTERVAL):\n",
    "    # Adversarial ground truths\n",
    "    valid = -np.ones((batch_size, 1))\n",
    "    fake = np.ones((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(TRAINING_RATIO):\n",
    "\n",
    "            # Use TensorFlow dataset direcrlt\n",
    "            for imgs, _ in dataset.take(1):\n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, NOISE_DIM))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = generator_512.predict(noise)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = discriminator_512.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = discriminator_512.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # Clip discriminator weights (for WGAN)\n",
    "                for l in discriminator_512.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "        # Train the generator\n",
    "        g_loss = combined.train_on_batch(noise, valid)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"{epoch}/{epochs} [D loss: {d_loss} | G loss: {g_loss}]\")\n",
    "\n",
    "        # Save generated images at save intervals\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(generator_512, epoch)\n",
    "\n",
    "\n",
    "def save_imgs(generator, epoch, save_path=\"gan_images\", num_samples=25):\n",
    "    \"\"\"\n",
    "    Saves generated images for visualization.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (num_samples, NOISE_DIM))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images from [-1, 1] to [0, 1]\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        plt.imshow(gen_imgs[i])\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{save_path}/image_at_epoch_{epoch}_sample_{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# start training:\n",
    "train_gan_512(celeba_dataset_processed, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
